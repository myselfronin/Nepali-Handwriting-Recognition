# -*- coding: utf-8 -*-
"""MajorProjectDevnagariCNN (1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1q7jyfSaBpasuGr5TzgiN6X7Fx1-VYSuw
"""

!pip install -q tensorflow==2.0.0-beta1 tensorflow-gpu==2.0.0-beta1

import tensorflow as tf
tf.compat.v1.disable_eager_execution()

#taken from this StackOverflow answer: https://stackoverflow.com/a/39225039
import requests

def download_file_from_google_drive(id, destination):
    URL = "https://docs.google.com/uc?export=download"

    session = requests.Session()

    response = session.get(URL, params = { 'id' : id }, stream = True)
    token = get_confirm_token(response)

    if token:
        params = { 'id' : id, 'confirm' : token }
        response = session.get(URL, params = params, stream = True)

    save_response_content(response, destination)    

def get_confirm_token(response):
    for key, value in response.cookies.items():
        if key.startswith('download_warning'):
            return value

    return None

def save_response_content(response, destination):
    CHUNK_SIZE = 32768

    with open(destination, "wb") as f:
        for chunk in response.iter_content(CHUNK_SIZE):
            if chunk: # filter out keep-alive new chunks
                f.write(chunk)

download_file_from_google_drive('1eeEF1iNzYHU_UiyKyJOhTTapUW2B8CzF','/content/data.zip')

!unzip -q '/content/data.zip'

from tensorflow.python.keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(
    rescale=1./255,
    shear_range=0.2,
    rotation_range=15,
    validation_split =0.2)


test_datagen = ImageDataGenerator(
    rescale=1./255, 
  )

train_generator = train_datagen.flow_from_directory(
    '/content/Dataset/',
    target_size=(28, 28),
    batch_size=64,
    color_mode = 'grayscale',
    shuffle = True,
    class_mode='categorical',
    subset = 'training',
 )

valid_generator = train_datagen.flow_from_directory(
    directory="/content/Dataset/",
    target_size=(28, 28),
    color_mode="grayscale",
    batch_size=64,
    class_mode="categorical",
    shuffle=True,
    subset = "validation",
)

from tensorflow.python.keras.models import Model
from tensorflow.python.keras.layers import Input,Dense,Dropout
from tensorflow.python.keras.layers import Conv2D, MaxPooling2D, Flatten

#Network Parameters
input_shape = (28,28,1)
kernel_size = 3
filters = 64
dropout = 0.3

#user functional API to build CNN Layers

inputs = Input(shape=input_shape)
x = Conv2D(filters = filters,
           kernel_size = kernel_size,
           activation = 'relu')(inputs)
x = MaxPooling2D()(x)
x = Conv2D(filters = filters,
           kernel_size = kernel_size,
           activation = 'relu')(x)

#image to vector before connecting to dense layer

x = Flatten()(x)

#dropout regularization

x = Dropout(dropout)(x)

outputs = Dense(24, activation = 'softmax')(x)

model = Model(inputs = inputs, outputs = outputs)

model.summary()

# Convolutional Neural Network
from tensorflow.python.keras.utils import plot_model
plot_model(model, to_file='convolution_neural_network.png',show_shapes = True)

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip
!unzip ngrok-stable-linux-amd64.zip

!mkdir log_dir

log_dir='log_dir'

get_ipython().system_raw(
    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'
    .format(log_dir)
)

get_ipython().system_raw('./ngrok authtoken 3B7pn9NBtoPA5qBzWAnxC_MJtkbzVtAKAiSEKrUQKQ &')
get_ipython().system_raw('./ngrok http 6006 &')
! curl -s http://localhost:4040/api/tunnels | python3 -c \
    "import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])"

from tensorflow.python.keras.callbacks import TensorBoard

callbacks = [TensorBoard(log_dir, update_freq='batch')]

model.fit_generator(train_generator,epochs = 32, steps_per_epoch=19200//128,validation_steps=4800//128,validation_data=valid_generator, callbacks=callbacks)

model.save('majorProjectV1.h5')

from google.colab import drive
drive.mount('/content/drive')

